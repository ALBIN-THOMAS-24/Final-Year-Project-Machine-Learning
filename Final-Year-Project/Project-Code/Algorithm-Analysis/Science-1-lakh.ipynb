{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Science1lakh.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUuNirVSZ60P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5519aa68-4912-4a71-b61f-9e691badc47d"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "data = pd.read_csv('/content/sample_data/Science1Lakh.csv')\n",
        "data.head()\n",
        "\n",
        "#LABEL ENCODING CONVERT CATEGORICAL DATA TO NUMERICAL DATA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "l1=LabelEncoder()\n",
        "data['TEAM-WORK']=l1.fit_transform(data['TEAM-WORK'])\n",
        "data['INTEREST']=l1.fit_transform(data['INTEREST'])\n",
        "data['COMPETIVE-EXAM-WINNER']=l1.fit_transform(data['COMPETIVE-EXAM-WINNER'])\n",
        "data['LEADERSHIP-SKILL']=l1.fit_transform(data['LEADERSHIP-SKILL'])\n",
        "data['WORK-LIFE-BALANCE']=l1.fit_transform(data['WORK-LIFE-BALANCE'])\n",
        "data['CERTIFICATIONS']=l1.fit_transform(data['CERTIFICATIONS'])\n",
        "data['SELF-LEARNING-CAPABILITY']=l1.fit_transform(data['SELF-LEARNING-CAPABILITY'])\n",
        "\n",
        "\n",
        "#CONVERT SUBJECT GRADES TO  NUMBER \n",
        "grade={\"PHYSICS\":{\"D\":45,\"C\":60,\"B\":70,\"B+\":75,\"A\":85,\"A \":85,\"A+\":90},\n",
        "       \"CHEMISTRY\":{\"D\":45,\"C\":60,\"B\":70,\"B+\":75,\"A\":85,\"A \":85,\"A+\":90},\n",
        "       \"MATHS\":{\"D\":45,\"C\":60,\"B\":70,\"B+\":75,\"A\":85,\"A \":85,\"A+\":90},\n",
        "       \"BIOLOGY\":{\"D\":45,\"C\":60,\"B\":70,\"B+\":75,\"A\":85,\"A \":85,\"A+\":90},\n",
        "       \"COMPUTER\":{\"D\":45,\"C\":60,\"B\":70,\"B+\":75,\"A\":85,\"A \":85,\"A+\":90},\n",
        "       \"LANGUAGE\":{\"D\":45,\"C\":60,\"B\":70,\"B+\":75,\"A\":85,\"A \":85,\"A+\":90},\n",
        "       \"SOCIO-ECONOMIC-FACTORS\":{\"PERSONAL-PREFERENCE\":1,\"JOB-SECURITY\":2,\"ECONOMIC-STATUS\":3,\"OTHERS\":4},\n",
        "       \"M-SCORE\":{\"HIGH\":90,\"MEDIUM\":70,\"LOW\":50}\n",
        "      }\n",
        "data=data.replace(grade)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#TRAIN-TEST SPLIT\n",
        "X=data.drop(['CAREER'], axis = 1) #FEATURES\n",
        "Y=data['CAREER'] #OUTPUT LABELS\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "#FEATURE SCALING\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "\n",
        "# KNN Algorithm\n",
        "print(\"***********************KNN***************************\\n\")\n",
        "import time\n",
        "start=time.time()\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "knn = KNeighborsClassifier(n_neighbors = 4) \n",
        "knn.fit(X_train, Y_train) \n",
        "Y_pred = knn.predict(X_test) \n",
        "end=time.time()\n",
        "print(\"Time=\",end-start)\n",
        "print(\"Predicted Value :\")\n",
        "print(Y_pred)\n",
        "\n",
        "#CONFUSION MATRIX USED FOR MODEL EVALUATION   \n",
        "print(\"\\nConfusion Matrix : model evaluation\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "    \n",
        "print(\"\\n Classification report :\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "\n",
        "#MODEL ACCURACY    \n",
        "print(\"\\nKNN Accuracy: \")\n",
        "from sklearn import metrics\n",
        "print((metrics.accuracy_score(Y_test, Y_pred))*100)\n",
        "\n",
        "\n",
        "#NAIVE-BAYES\n",
        "print(\"*****************NAIVE-BAYES*******************\\n\")\n",
        "import time\n",
        "Start = time.time ()\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "naive_bayes = GaussianNB() \n",
        "naive_bayes.fit(X_train, Y_train) \n",
        "Y_pred = naive_bayes.predict(X_test) \n",
        "print(\"Predicted Value :\")\n",
        "print(Y_pred)\n",
        "    \n",
        "print(\"\\nConfusion Matrix : model evaluation\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "    \n",
        "print(\"\\n Classification report :\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "    \n",
        "print(\"\\nNaive-Bayes Accuracy : \")\n",
        "from sklearn import metrics\n",
        "print((metrics.accuracy_score(Y_test, Y_pred))*100)\n",
        "a1=(metrics.accuracy_score(Y_test, Y_pred))*100\n",
        "end= time.time()\n",
        "b1 = str(round(end-Start,2))\n",
        "print(b1)\n",
        "\n",
        "#DECISION TREE\n",
        "print(\"******************DECISION TREE***********************\\n\")\n",
        "import time\n",
        "Start = time.time ()\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "Decision_tree= DecisionTreeClassifier(criterion = 'gini') \n",
        "Decision_tree.fit(X_train, Y_train)\n",
        "Y_pred = Decision_tree.predict(X_test) \n",
        "print(\"Predicted Value :\")\n",
        "print(Y_pred)\n",
        "    \n",
        "print(\"\\nConfusion Matrix : model evaluation\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "    \n",
        "print(\"\\n Classification report :\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "    \n",
        "print(\"\\nDecision Tree Accuracy : \")\n",
        "from sklearn import metrics\n",
        "print((metrics.accuracy_score(Y_test, Y_pred))*100)\n",
        "a2=(metrics.accuracy_score(Y_test, Y_pred))*100\n",
        "end= time.time()\n",
        "b2=str(round(end-Start,2))\n",
        "print(b2)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#LOGISTIC-REGRESSION\n",
        "print(\"*****************LOGISTIC-REGRESSION*********************\\n\")\n",
        "import time\n",
        "Start = time.time ()\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "logistic = LogisticRegression(max_iter=9000) \n",
        "logistic.fit(X_train, Y_train)\n",
        "Y_pred = logistic.predict(X_test) \n",
        "print(\"Predicted Value :\")\n",
        "print(Y_pred)\n",
        "    \n",
        "print(\"\\nConfusion Matrix : model evaluation\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "    \n",
        "print(\"\\n Classification report :\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "    \n",
        "print(\"\\nLogistic Regression Accuracy : \")\n",
        "from sklearn import metrics\n",
        "print((metrics.accuracy_score(Y_test, Y_pred))*100)\n",
        "a3=(metrics.accuracy_score(Y_test, Y_pred))*100\n",
        "end= time.time()\n",
        "b3=str(round(end-Start,2))\n",
        "print(b3)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Adaboost Classifier\n",
        "import time\n",
        "start=time.time()\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "abc = AdaBoostClassifier()\n",
        "# Train Adaboost Classifer\n",
        "model = abc.fit(X_train, Y_train)\n",
        "Y_pred = model.predict(X_test)\n",
        "print(\"Adaboost-ACCURACY => \"+str(metrics.accuracy_score(Y_test, Y_pred)*100)+str(\" %\"))\n",
        "end=time.time()\n",
        "print(\"time=\"+str(end-start))\n",
        "#CLASSIFICATION REPORT\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "#CONFUSION MATRIX\n",
        "print(confusion_matrix(Y_test,Y_pred))\n",
        "print('\\n')\n",
        "print(classification_report(Y_test,Y_pred))\n",
        "\n",
        "#two hidden layers - MLP\n",
        "import time\n",
        "start=time.time()\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp= MLPClassifier(hidden_layer_sizes=(8,8), activation='relu', solver='adam',max_iter=200)\n",
        "mlp.fit(X_train,Y_train)\n",
        "Y_pred=(mlp.predict(X_test))\n",
        "print(\"MLP-ACCURACY => \"+str(metrics.accuracy_score(Y_test, Y_pred)*100)+str(\" %\"))\n",
        "end=time.time()\n",
        "print(\"time=\"+str(end-start))\n",
        "#CLASSIFICATION REPORT\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "#CONFUSION MATRIX\n",
        "print(confusion_matrix(Y_test,Y_pred))\n",
        "print('\\n')\n",
        "print(classification_report(Y_test,Y_pred))\n",
        "\n",
        "#ANN\n",
        "#FEATURE SCALING\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "print(X_train)\n",
        "\n",
        "print(\"\\nONE-HOT-ENCODING\")\n",
        "#one-hot-encoding to convert multiclass values \n",
        "print(Y_train)\n",
        "from keras.utils import to_categorical\n",
        "Y_train= to_categorical(Y_train)\n",
        "Y_test= to_categorical(Y_test)\n",
        "print(Y_train)\n",
        "\n",
        "#BUILDING ANN\n",
        "import tensorflow as tf\n",
        "ann=tf.keras.models.Sequential()\n",
        "#Add input layer\n",
        "ann.add(tf.keras.layers.Dense(units=10,activation='relu'))\n",
        "#Add 3 hidden Layers\n",
        "ann.add(tf.keras.layers.Dense(units=10,activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=10,activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=10,activation='relu'))\n",
        "#output layer\n",
        "ann.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "\n",
        "#TRAIN ANN\n",
        "ann.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "ann.fit(X_train,Y_train,batch_size=32,epochs=20)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "***********************KNN***************************\n",
            "\n",
            "Time= 78.36897945404053\n",
            "Predicted Value :\n",
            "[2 1 1 ... 1 2 1]\n",
            "\n",
            "Confusion Matrix : model evaluation\n",
            "[[4404 1089  745]\n",
            " [1636 5258  845]\n",
            " [1302 1332 3389]]\n",
            "\n",
            " Classification report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.60      0.71      0.65      6238\n",
            "           2       0.68      0.68      0.68      7739\n",
            "           3       0.68      0.56      0.62      6023\n",
            "\n",
            "    accuracy                           0.65     20000\n",
            "   macro avg       0.66      0.65      0.65     20000\n",
            "weighted avg       0.66      0.65      0.65     20000\n",
            "\n",
            "\n",
            "KNN Accuracy: \n",
            "65.255\n",
            "*****************NAIVE-BAYES*******************\n",
            "\n",
            "Predicted Value :\n",
            "[3 1 1 ... 2 3 1]\n",
            "\n",
            "Confusion Matrix : model evaluation\n",
            "[[1961 2595 1682]\n",
            " [1337 4584 1818]\n",
            " [ 974 2414 2635]]\n",
            "\n",
            " Classification report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.46      0.31      0.37      6238\n",
            "           2       0.48      0.59      0.53      7739\n",
            "           3       0.43      0.44      0.43      6023\n",
            "\n",
            "    accuracy                           0.46     20000\n",
            "   macro avg       0.46      0.45      0.45     20000\n",
            "weighted avg       0.46      0.46      0.45     20000\n",
            "\n",
            "\n",
            "Naive-Bayes Accuracy : \n",
            "45.9\n",
            "0.11\n",
            "******************DECISION TREE***********************\n",
            "\n",
            "Predicted Value :\n",
            "[3 1 1 ... 1 2 1]\n",
            "\n",
            "Confusion Matrix : model evaluation\n",
            "[[4145 1123  970]\n",
            " [1145 5667  927]\n",
            " [ 950  953 4120]]\n",
            "\n",
            " Classification report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.66      0.66      0.66      6238\n",
            "           2       0.73      0.73      0.73      7739\n",
            "           3       0.68      0.68      0.68      6023\n",
            "\n",
            "    accuracy                           0.70     20000\n",
            "   macro avg       0.69      0.69      0.69     20000\n",
            "weighted avg       0.70      0.70      0.70     20000\n",
            "\n",
            "\n",
            "Decision Tree Accuracy : \n",
            "69.66\n",
            "0.98\n",
            "\n",
            "\n",
            "\n",
            "*****************LOGISTIC-REGRESSION*********************\n",
            "\n",
            "Predicted Value :\n",
            "[1 3 1 ... 2 3 1]\n",
            "\n",
            "Confusion Matrix : model evaluation\n",
            "[[2623 2513 1102]\n",
            " [1541 4858 1340]\n",
            " [1176 2732 2115]]\n",
            "\n",
            " Classification report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.49      0.42      0.45      6238\n",
            "           2       0.48      0.63      0.54      7739\n",
            "           3       0.46      0.35      0.40      6023\n",
            "\n",
            "    accuracy                           0.48     20000\n",
            "   macro avg       0.48      0.47      0.47     20000\n",
            "weighted avg       0.48      0.48      0.47     20000\n",
            "\n",
            "\n",
            "Logistic Regression Accuracy : \n",
            "47.980000000000004\n",
            "1.03\n",
            "\n",
            "\n",
            "\n",
            "Adaboost-ACCURACY => 50.94 %\n",
            "time=4.750614881515503\n",
            "[[2616 2473 1149]\n",
            " [1308 5242 1189]\n",
            " [1196 2497 2330]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.51      0.42      0.46      6238\n",
            "           2       0.51      0.68      0.58      7739\n",
            "           3       0.50      0.39      0.44      6023\n",
            "\n",
            "    accuracy                           0.51     20000\n",
            "   macro avg       0.51      0.49      0.49     20000\n",
            "weighted avg       0.51      0.51      0.50     20000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLP-ACCURACY => 60.49 %\n",
            "time=47.2858669757843\n",
            "[[3452 1774 1012]\n",
            " [1180 5169 1390]\n",
            " [ 839 1707 3477]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      0.55      0.59      6238\n",
            "           2       0.60      0.67      0.63      7739\n",
            "           3       0.59      0.58      0.58      6023\n",
            "\n",
            "    accuracy                           0.60     20000\n",
            "   macro avg       0.61      0.60      0.60     20000\n",
            "weighted avg       0.61      0.60      0.60     20000\n",
            "\n",
            "[[ 0.04900114 -1.75934165 -0.67635584 ...  0.88422636  0.90624847\n",
            "   0.631833  ]\n",
            " [ 0.32207832 -0.11064796 -0.67635584 ... -1.13093213 -1.10345014\n",
            "   0.631833  ]\n",
            " [ 0.59515549  1.53804574 -0.11093548 ...  0.88422636  0.90624847\n",
            "   0.631833  ]\n",
            " ...\n",
            " [-0.01926815 -0.11064796  1.58532563 ...  0.88422636  0.90624847\n",
            "  -1.58269669]\n",
            " [-0.56542251 -0.66021252  1.01990526 ... -1.13093213 -1.10345014\n",
            "   0.631833  ]\n",
            " [ 0.39034761  0.98848118 -0.67635584 ...  0.88422636  0.90624847\n",
            "   0.631833  ]]\n",
            "\n",
            "ONE-HOT-ENCODING\n",
            "34555    3\n",
            "4442     1\n",
            "50811    1\n",
            "45326    3\n",
            "57679    2\n",
            "        ..\n",
            "31019    1\n",
            "44566    3\n",
            "95816    2\n",
            "72173    3\n",
            "89256    2\n",
            "Name: CAREER, Length: 80000, dtype: int64\n",
            "[[0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]]\n",
            "Epoch 1/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0508 - accuracy: 0.4574\n",
            "Epoch 2/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.9131 - accuracy: 0.5513\n",
            "Epoch 3/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.8819 - accuracy: 0.5732\n",
            "Epoch 4/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.8569 - accuracy: 0.5873\n",
            "Epoch 5/20\n",
            "2500/2500 [==============================] - 3s 1ms/step - loss: 0.8401 - accuracy: 0.5995\n",
            "Epoch 6/20\n",
            "2500/2500 [==============================] - 3s 1ms/step - loss: 0.8306 - accuracy: 0.6068\n",
            "Epoch 7/20\n",
            "2500/2500 [==============================] - 3s 1ms/step - loss: 0.8281 - accuracy: 0.6102\n",
            "Epoch 8/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.8159 - accuracy: 0.6147\n",
            "Epoch 9/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.8023 - accuracy: 0.6227\n",
            "Epoch 10/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7938 - accuracy: 0.6288\n",
            "Epoch 11/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7906 - accuracy: 0.6292\n",
            "Epoch 12/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7841 - accuracy: 0.6333\n",
            "Epoch 13/20\n",
            "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7807 - accuracy: 0.6353\n",
            "Epoch 14/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7791 - accuracy: 0.6334\n",
            "Epoch 15/20\n",
            "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7766 - accuracy: 0.6327\n",
            "Epoch 16/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7718 - accuracy: 0.6353\n",
            "Epoch 17/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7662 - accuracy: 0.6371\n",
            "Epoch 18/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7697 - accuracy: 0.6352\n",
            "Epoch 19/20\n",
            "2500/2500 [==============================] - 3s 1ms/step - loss: 0.7668 - accuracy: 0.6370\n",
            "Epoch 20/20\n",
            "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7653 - accuracy: 0.6367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7dbb7c390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}